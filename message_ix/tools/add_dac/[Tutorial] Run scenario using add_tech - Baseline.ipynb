{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ce2dbbc",
   "metadata": {},
   "source": [
    "This script is to add data general. \n",
    "Import all required tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db473272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ixmp\n",
    "import message_ix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from collections.abc import Mapping\n",
    "from itertools import repeat\n",
    "from message_ix.models import MESSAGE_ITEMS\n",
    "from message_ix.utils import make_df\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "mp = ixmp.Platform('local')\n",
    "#mp.scenario_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664097c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d4cf7f5",
   "metadata": {},
   "source": [
    "This part is just to generate a dummy scenario as basis for adding technology parameters. Need to be removed once integrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "34cf0deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to import scenario from data base and clone to local\n",
    "'''\n",
    "model = \"ENGAGE_SSP2_v4.1.7\"\n",
    "\n",
    "base = message_ix.Scenario(mp, model=model, scenario=\"NPi2020_Baseline\")\n",
    "base_local = base.clone(\n",
    "    \"GENIE_sandbox\",\n",
    "    \"baseline\",\n",
    "    \"importing scenario from database to local platform\",\n",
    "    platform=mp_local, # keep_solution=False, \n",
    ")\n",
    "'''\n",
    "base = message_ix.Scenario(mp, model='GENIE_sandbox', scenario=\"baseline\")\n",
    "\n",
    "scen = base.clone(\n",
    "    \"GENIE_sandbox\",\n",
    "    \"add_tech_baseline\",\n",
    "    \"introducing the add_tech feature on MESSAGEix\", \n",
    "    keep_solution=False, \n",
    ")\n",
    "scen.check_out()\n",
    "\n",
    "year_df = scen.vintage_and_active_years()\n",
    "vintage_years, act_years = year_df[\"year_vtg\"], year_df[\"year_act\"]\n",
    "model_horizon = scen.set(\"year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec4d656",
   "metadata": {},
   "source": [
    "## Add `Tech Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce0556e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DAC_all_data.yaml','r') as stream: # LT_tech_data, LT_system_data, LT_dac_data\n",
    "    tech_data = yaml.safe_load(stream)\n",
    "\n",
    "# create dictionary of parameter indices list\n",
    "par_idx = {}\n",
    "data = {}\n",
    "for tech in set(tech_data) - set(['model_data']):\n",
    "    par_idx.update({tech: {par: {idx: [] for idx in list(MESSAGE_ITEMS[par].get('idx_names'))} \n",
    "                           for par in set(tech_data[tech])}})\n",
    "    data.update({tech: {par: [] for par in list(par_idx[tech].keys())}})\n",
    "\n",
    "first_active_year = tech_data['model_data'].get('first_active_year')\n",
    "years_vtg_act = scen.vintage_and_active_years()\n",
    "years_vtg_act = years_vtg_act[years_vtg_act['year_vtg'] >= first_active_year]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8e340f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If those are not provided, then this block of code is needed to retrieve them from the data input\n",
    "\n",
    "regions = []\n",
    "emissions = []\n",
    "times = []\n",
    "modes = []\n",
    "commodities = []\n",
    "levels = []\n",
    "relations = []\n",
    "\n",
    "set_elements_dict = {\n",
    "    'node_loc'   :{'data': regions,     'name':'node'},\n",
    "    'emission'   :{'data': emissions,   'name':'emission'},\n",
    "    'mode'       :{'data': modes,       'name':'mode'},\n",
    "    'time'       :{'data': times,       'name':'time'},\n",
    "    'commodity'  :{'data': commodities, 'name':'commodity'},\n",
    "    'level'      :{'data': levels,      'name':'level'},\n",
    "    'time_origin':{'data': times,       'name':'time'},\n",
    "    'time_dest'  :{'data': times,       'name':'time'},\n",
    "    'relation'   :{'data': relations,   'name':'relation'},\n",
    "    'node_rel'   :{'data': regions,     'name':'node'},\n",
    "}   \n",
    "\n",
    "for tec in par_idx.keys():\n",
    "    if tec not in set(scen.set(\"technology\")):\n",
    "            scen.add_set('technology',tec)\n",
    "    for par in par_idx[tec]:\n",
    "        for idx in set_elements_dict.keys():\n",
    "            if idx in par_idx[tec][par].keys():\n",
    "                if len(set_elements_dict[idx]['data']) != 0:\n",
    "                    par_idx[tec][par][idx] = set_elements_dict[idx]['data']\n",
    "                elif len(set_elements_dict[idx]['data']) == 0:\n",
    "                    if tech_data['model_data'].get(tec,{}).get(par,{}).get(idx,{}) != {}:\n",
    "                        par_idx[tec][par][idx] = list(tech_data['model_data'][tec][par][idx].keys())\n",
    "                    else:\n",
    "                        if idx in ['node_loc','mode']: # to not including 'World' and 'all' mode\n",
    "                            par_idx[tec][par][idx] = list(scen.set(set_elements_dict[idx]['name']))[1:]\n",
    "                        else:\n",
    "                            par_idx[tec][par][idx] = list(scen.set(set_elements_dict[idx]['name']))\n",
    "                    # check and add set if not already exist\n",
    "                    for e_idx in par_idx[tec][par][idx]:\n",
    "                        if e_idx not in set(scen.set(set_elements_dict[idx]['name'])):\n",
    "                            scen.add_set(set_elements_dict[idx]['name'],e_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103d6759",
   "metadata": {},
   "source": [
    "#### Creating basic dataframe to be filled in later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b6f681b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create basic DataFrame and expand according to model_data input\n",
    "count = 0\n",
    "for tech, par_dict in tech_data.items():\n",
    "    if tech != 'model_data':\n",
    "        for par, par_data in par_dict.items():\n",
    "            if not isinstance(par_data, Mapping):\n",
    "                par_data = {'value': par_data, 'unit': '-'}\n",
    "            # identify parameters by year dimension\n",
    "            # then add the year data as kwargs as input for basic dataframe\n",
    "            if all(e in par_idx[tech][par] for e in ['year_vtg','year_act']):\n",
    "                kwargs = {'year_vtg': years_vtg_act['year_vtg'],\n",
    "                          'year_act': years_vtg_act['year_act']}\n",
    "            elif 'year_vtg' in par_idx[tech][par]:\n",
    "                kwargs = {'year_vtg': sorted(set(years_vtg_act['year_vtg']))}\n",
    "            else:\n",
    "                kwargs = {'year_act': sorted(set(years_vtg_act['year_act']))}\n",
    "                # if 'year_rel' is present, the values are assumed from 'year_act' values\n",
    "                if 'year_rel' in par_idx[tech][par]:\n",
    "                    kwargs.update({'year_rel': sorted(set(years_vtg_act['year_act']))})\n",
    "                                \n",
    "            # create parameter's basic dataframe and \n",
    "            # add it to the data parameter list\n",
    "            data[tech][par].append(\n",
    "                make_df(\n",
    "                    par,\n",
    "                    technology=tech,\n",
    "                    value=par_data['value'],\n",
    "                    unit=par_data['unit'],\n",
    "                    **kwargs,\n",
    "                ))\n",
    "\n",
    "            # duplicate the basic data using the length of each set\n",
    "            # as the duplication factor\n",
    "            for s in set_elements_dict.keys():\n",
    "                if s in par_idx[tech][par] and s not in ['year_vtg','year_act']:\n",
    "                    elist = par_idx[tech][par][s]\n",
    "                    data[tech][par] = data[tech][par]*len(elist)\n",
    "                    for e in range(len(elist)):\n",
    "                        kwarg = {s:elist[e]}\n",
    "                        # print(tech,par,s)\n",
    "                        data[tech][par][e] = data[tech][par][e].assign(**kwarg)\n",
    "                data[tech][par] = [pd.concat(data[tech][par]).reset_index(drop=True)]\n",
    "                if 'node_origin' in data[tech][par][0].columns:\n",
    "                    data[tech][par][0]['node_origin'] = data[tech][par][0]['node_loc']\n",
    "                if 'node_dest' in data[tech][par][0].columns:\n",
    "                    data[tech][par][0]['node_dest'] = data[tech][par][0]['node_loc']\n",
    "                if 'node_rel' in data[tech][par][0].columns:\n",
    "                    data[tech][par][0]['node_rel'] = data[tech][par][0]['node_loc']\n",
    "                    \n",
    "data = {t: {k: pd.concat(v).reset_index(drop=True) \n",
    "            for k, v in data[t].items()} for t in data.keys()}\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6d55acdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Expanded DataFrame\n",
    "data_expand ={tech: {par: [] for par in data[tech].keys()} for tech in data.keys()}\n",
    "\n",
    "for tech, par_data in tech_data['model_data'].items():\n",
    "    if tech != 'first_active_year':\n",
    "        for par in data[tech].keys():\n",
    "            multiplier = []\n",
    "            for i in range(len(data[tech][par])):\n",
    "                # Calculate multipliers for each element in a dimensional array.\n",
    "                # For each element, this function searches for corresponding factors\n",
    "                # in the model-specific data (model_data).\n",
    "                # If no factors are found, the multiplier is set to 1.\n",
    "                # If factors are found, the function uses the factor that matches\n",
    "                # the corresponding element in the data[par] row.\n",
    "\n",
    "                # get regional multiplier from model_data\n",
    "                #m_reg = par_data.get(par,{}).get('node_loc',{}).get(reg,1)\n",
    "                m_node_loc = (par_data.get(par,{}).get('node_loc',{})\n",
    "                              .get(data[tech][par].get('node_loc',{}).get(i),1))\n",
    "                \n",
    "                # get year_vtg escalation rate from model_data\n",
    "                # then calculate year_vtg multiplier\n",
    "                # m_year_vtg = (1+rate)**delta_years\n",
    "                m_year_vtg = (((1+par_data.get(par,{}).get('year_vtg',{}).get('rate',0)) \n",
    "                              **(data[tech][par]['year_vtg'][i]-first_active_year)) \n",
    "                              if 'year_vtg' in data[tech][par].columns else 1)\n",
    "\n",
    "                # same as m_year_vtg\n",
    "                # m_year_act = (1+rate)**(year_act-year_vtg) if both years present\n",
    "                # m_year_act = (1+rate)**(year_act-first_active_year) if no year_vtg\n",
    "                m_year_act = (((1+par_data.get(par,{}).get('year_act',{}).get('rate',0))\n",
    "                              **(data[tech][par].get('year_act',{})\n",
    "                                 .get(i,0)\n",
    "                                 -(data[tech][par]['year_vtg'][i] \n",
    "                                   if 'year_vtg' in data[tech][par].columns else first_active_year)))\n",
    "                             if 'year_act' in data[tech][par].columns else 1)\n",
    "\n",
    "                m_year_rel = (((1+par_data.get(par,{}).get('year_rel',{}).get('rate',0))\n",
    "                              **(data[tech][par].get('year_rel',{})\n",
    "                                 .get(i,0)\n",
    "                                 -(data[tech][par]['year_vtg'][i] \n",
    "                                   if 'year_vtg' in data[tech][par].columns else\n",
    "                                   (data[tech][par]['year_act'][i] if 'year_act' in data[tech][par].columns \n",
    "                                    else first_active_year))))\n",
    "                             if 'year_rel' in data[tech][par].columns else 1)\n",
    "\n",
    "                \n",
    "                # get mode multiplier from model_data\n",
    "                m_mode = (par_data.get(par,{}).get('mode',{})\n",
    "                          .get(data[tech][par].get('mode',{}).get(i),1))\n",
    "\n",
    "                # get emission multiplier from model_data\n",
    "                m_emission = (par_data.get(par,{}).get('emission',{})\n",
    "                              .get(data[tech][par].get('emission',{}).get(i),1))\n",
    "\n",
    "                # get relation multiplier\n",
    "                m_relation = (par_data.get(par,{}).get('relation',{})\n",
    "                              .get(data[tech][par].get('relation',{}).get(i),1))\n",
    "                \n",
    "\n",
    "                multiplier.append(\n",
    "                        np.prod([m_node_loc, \n",
    "                                 m_year_vtg, m_year_act, m_year_act, \n",
    "                                 m_mode, m_emission,m_relation,])\n",
    "                    )\n",
    "\n",
    "            value = data[tech][par]['value']*multiplier\n",
    "\n",
    "            \n",
    "            # assigning data expansion\n",
    "            data_expand[tech][par].append(\n",
    "                data[tech][par].assign(value=value)#, **kwargs)\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "328e874d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_loc': {'R11_AFR': 1,\n",
       "  'R11_CPA': 1,\n",
       "  'R11_EEU': 1,\n",
       "  'R11_FSU': 1,\n",
       "  'R11_LAM': 1,\n",
       "  'R11_MEA': 1,\n",
       "  'R11_NAM': 1,\n",
       "  'R11_PAO': 1,\n",
       "  'R11_PAS': 1,\n",
       "  'R11_SAS': 1,\n",
       "  'R11_WEU': 1},\n",
       " 'year_vtg': {'rate': -0.01}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_data['model_data']['LT_DAC']['inv_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e6aadbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = []\n",
    "for t in data_expand.keys():\n",
    "    for par in data_expand[t].keys():\n",
    "        if par not in all_params:\n",
    "            all_params.append(par)\n",
    "\n",
    "data_to_scenario = {par: [] for par in all_params}\n",
    "\n",
    "for k,v in data_expand.items():\n",
    "    for k2,v2 in v.items():\n",
    "        data_to_scenario[k2].append(v2[0])\n",
    "\n",
    "data_expand = {k: pd.concat(v) for k, v in data_to_scenario.items()}        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ba2b797",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('printed_tech_data.xlsx', engine='xlsxwriter', mode='w') as writer:\n",
    "    for sheet_name, sheet_data in data_expand.items():\n",
    "        sheet_data.to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b771de4",
   "metadata": {},
   "source": [
    "### Add data to scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2890fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "for par in data_expand.keys():\n",
    "    scen.add_par(par,data_expand[par])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf012d2",
   "metadata": {},
   "source": [
    "#### Adding other required input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3061e437",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_loc = [e for e in scen.set('node') if e not in ['World','R11_GLB']]\n",
    "year_act = [e for e in scen.set('year') if e >= 2025]\n",
    "\n",
    "# Creating dataframe for CO2_Emission_Global_Total relation\n",
    "CO2_global_par = []\n",
    "for tech in ['LT_DAC','HT_DAC']:\n",
    "    for reg in node_loc:\n",
    "        CO2_global_par.append(\n",
    "            make_df('relation_activity',\n",
    "                    relation='CO2_Emission_Global_Total',\n",
    "                    node_rel='R11_GLB',#node_rel,\n",
    "                    year_rel=year_act,\n",
    "                    node_loc=reg,\n",
    "                    technology=tech,#['LT_DAC','HT_DAC'],\n",
    "                    year_act=year_act,\n",
    "                    mode='M1',\n",
    "                    value=-1,\n",
    "                    unit='-',\n",
    "                ))\n",
    "CO2_global_par = pd.concat(CO2_global_par)\n",
    "\n",
    "# Adding the dataframe to the scenario\n",
    "scen.add_par('relation_activity',CO2_global_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "990ce9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_emission_list = ['co2_storage_pot']\n",
    "emission_list = ['CO2_storage']\n",
    "\n",
    "type_tec_list = ['co2_potential']\n",
    "technology_list = ['dacco2_tr_dis']\n",
    "\n",
    "if 'co2_storage_pot' not in scen.set('type_emission'):\n",
    "    scen.add_set('type_emission','co2_storage_pot')\n",
    "if 'co2_potential' not in scen.set('type_tec'):\n",
    "    scen.add_set('type_tec','co2_potential')\n",
    "    \n",
    "scen.add_set('cat_emission',['co2_storage_pot','CO2_storage'])\n",
    "scen.add_set('cat_tec',['co2_potential','dacco2_tr_dis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1cf489ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add emission bound\n",
    "#scen.add_par('bound_emission', ['World', 'TCE_CO2', 'all', 'cumulative'], value=2421.17, unit=\"tC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcbfbe2",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "32bf3996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3136094.25"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scen.commit(comment=\"Add DACs to baseline scenario\")\n",
    "scen.set_as_default()\n",
    "scen.solve(solve_options={'barcrossalg': '2','scaind':'1'})\n",
    "scen.var(\"OBJ\")[\"lvl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8838b4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc20751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d026830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f688d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92dd9c90",
   "metadata": {},
   "source": [
    "## Close connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f8e3cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.close_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0742df19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
